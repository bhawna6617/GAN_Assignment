{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f214de8",
   "metadata": {},
   "source": [
    "# question:-1,Use any GAN of your choice (preferably DCGAN) to generate images from noise. Perform the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d9e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate images from noise using a DCGAN (Deep Convolutional Generative Adversarial Network), we need to perform the following steps:\n",
    "\n",
    "# Setup the Environment: Ensure that we have the necessary libraries installed, such as TensorFlow or PyTorch, along with other dependencies.\n",
    "# Data Preparation: Use a dataset for training the GAN. Common datasets include MNIST, CIFAR-10, or CelebA.\n",
    "# Model Architecture: Define the generator and discriminator models for the DCGAN.\n",
    "# Training the DCGAN: Train the GAN by alternating between training the discriminator and the generator.\n",
    "# Generate Images: After training, use the generator to create images from random noise.\n",
    "# Let's go through these steps in detail.\n",
    "\n",
    "# 1. Setup the Environment\n",
    "# First, ensure that you have the required libraries installed. You can use either TensorFlow or PyTorch. For this example, I'll use PyTorch.\n",
    "\n",
    "# bash\n",
    "# Copy code\n",
    "# pip install torch torchvision\n",
    "# 2. Data Preparation\n",
    "# We'll use the MNIST dataset for simplicity. You can replace it with any other dataset of your choice.\n",
    "\n",
    "# 3. Model Architecture\n",
    "# Define the generator and discriminator models.\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Generator model\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, z_dim):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.gen = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(z_dim, 256, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.gen(x)\n",
    "\n",
    "# # Discriminator model\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.disc = nn.Sequential(\n",
    "#             nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(256, 1, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.disc(x)\n",
    "# 4. Training the DCGAN\n",
    "\n",
    "# # Hyperparameters\n",
    "# z_dim = 100\n",
    "# batch_size = 128\n",
    "# lr = 0.0002\n",
    "# num_epochs = 50\n",
    "\n",
    "# # Data loader\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5], [0.5])\n",
    "# ])\n",
    "\n",
    "# dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Initialize models\n",
    "# generator = Generator(z_dim).cuda()\n",
    "# discriminator = Discriminator().cuda()\n",
    "\n",
    "# # Optimizers\n",
    "# optim_gen = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# optim_disc = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# # Loss function\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for idx, (real, _) in enumerate(dataloader):\n",
    "#         real = real.cuda()\n",
    "#         batch_size = real.size(0)\n",
    "\n",
    "#         # Train Discriminator\n",
    "#         noise = torch.randn(batch_size, z_dim, 1, 1).cuda()\n",
    "#         fake = generator(noise)\n",
    "\n",
    "#         disc_real = discriminator(real).reshape(-1)\n",
    "#         disc_fake = discriminator(fake.detach()).reshape(-1)\n",
    "#         loss_disc = criterion(disc_real, torch.ones_like(disc_real)) + criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "\n",
    "#         optim_disc.zero_grad()\n",
    "#         loss_disc.backward()\n",
    "#         optim_disc.step()\n",
    "\n",
    "#         # Train Generator\n",
    "#         output = discriminator(fake).reshape(-1)\n",
    "#         loss_gen = criterion(output, torch.ones_like(output))\n",
    "\n",
    "#         optim_gen.zero_grad()\n",
    "#         loss_gen.backward()\n",
    "#         optim_gen.step()\n",
    "\n",
    "#         if idx % 100 == 0:\n",
    "#             print(f\"Epoch [{epoch}/{num_epochs}] Batch {idx}/{len(dataloader)} Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\")\n",
    "# 5. Generate Images\n",
    "# After training, use the generator to create images from random noise.\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Generate images\n",
    "# generator.eval()\n",
    "# noise = torch.randn(64, z_dim, 1, 1).cuda()\n",
    "# fake_images = generator(noise)\n",
    "\n",
    "# # Plot the generated images\n",
    "# fake_images = fake_images.cpu().detach()\n",
    "# grid = torchvision.utils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.imshow(grid.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "# This script sets up the DCGAN, trains it on the MNIST dataset, and generates images from noise. You can customize the dataset, model architecture, and hyperparameters as needed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ae64a",
   "metadata": {},
   "source": [
    "# A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c58b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the CIFAR-10 dataset to train a DCGAN and generate images once the learning is complete, we can follow a similar approach as outlined before. Hereâ€™s how to proceed with this task:\n",
    "\n",
    "# Step-by-Step Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "\n",
    "# bash\n",
    "# Copy code\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 dataset and preprocess it.\n",
    "\n",
    "# python\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchvision.utils as vutils\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Hyperparameters\n",
    "# z_dim = 100\n",
    "# batch_size = 128\n",
    "# lr = 0.0002\n",
    "# num_epochs = 50\n",
    "# image_size = 64\n",
    "# channels = 3\n",
    "\n",
    "# # Transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(image_size),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5 for _ in range(channels)], [0.5 for _ in range(channels)])\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# dataset = datasets.CIFAR10(root='data', train=True, transform=transform, download=True)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# 3. Model Architecture\n",
    "# Define the generator and discriminator models tailored for CIFAR-10.\n",
    "\n",
    "\n",
    "# # Generator model\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, z_dim):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.gen = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(z_dim, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64, channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.gen(x)\n",
    "\n",
    "# # Discriminator model\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.disc = nn.Sequential(\n",
    "#             nn.Conv2d(channels, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.disc(x)\n",
    "# 4. Training the DCGAN\n",
    "\n",
    "# # Initialize models\n",
    "# generator = Generator(z_dim).cuda()\n",
    "# discriminator = Discriminator().cuda()\n",
    "\n",
    "# # Optimizers\n",
    "# optim_gen = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# optim_disc = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# # Loss function\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for idx, (real, _) in enumerate(dataloader):\n",
    "#         real = real.cuda()\n",
    "#         batch_size = real.size(0)\n",
    "\n",
    "#         # Train Discriminator\n",
    "#         noise = torch.randn(batch_size, z_dim, 1, 1).cuda()\n",
    "#         fake = generator(noise)\n",
    "\n",
    "#         disc_real = discriminator(real).reshape(-1)\n",
    "#         disc_fake = discriminator(fake.detach()).reshape(-1)\n",
    "#         loss_disc = criterion(disc_real, torch.ones_like(disc_real)) + criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "\n",
    "#         optim_disc.zero_grad()\n",
    "#         loss_disc.backward()\n",
    "#         optim_disc.step()\n",
    "\n",
    "#         # Train Generator\n",
    "#         output = discriminator(fake).reshape(-1)\n",
    "#         loss_gen = criterion(output, torch.ones_like(output))\n",
    "\n",
    "#         optim_gen.zero_grad()\n",
    "#         loss_gen.backward()\n",
    "#         optim_gen.step()\n",
    "\n",
    "#         if idx % 100 == 0:\n",
    "#             print(f\"Epoch [{epoch}/{num_epochs}] Batch {idx}/{len(dataloader)} Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "\n",
    "#     # Save images at the end of each epoch\n",
    "#     with torch.no_grad():\n",
    "#         fake_images = generator(noise).detach().cpu()\n",
    "#         img_grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "#         plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "#         plt.show()\n",
    "# 5. Generate Images\n",
    "# After training, generate images from random noise and visualize them.\n",
    "\n",
    "\n",
    "# # Generate images\n",
    "# generator.eval()\n",
    "# with torch.no_grad():\n",
    "#     noise = torch.randn(64, z_dim, 1, 1).cuda()\n",
    "#     fake_images = generator(noise).detach().cpu()\n",
    "\n",
    "# # Plot the generated images\n",
    "# grid = vutils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "# plt.show()\n",
    "# This complete script will train a DCGAN on the CIFAR-10 dataset and generate images after training. You can adjust the hyperparameters, model architecture, and dataset as needed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94805ac",
   "metadata": {},
   "source": [
    "# B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f04fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the generator and discriminator losses during the training process and ascertain the convergence of the GAN, we can modify the training loop to keep track of the losses and then plot them after training. Hereâ€™s how you can do it:\n",
    "\n",
    "# Modified Training Loop with Loss Tracking\n",
    "# First, let's add lists to keep track of the losses for the generator and discriminator.\n",
    "\n",
    "# python\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# # Lists to keep track of generator and discriminator losses\n",
    "# gen_losses = []\n",
    "# disc_losses = []\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for idx, (real, _) in enumerate(dataloader):\n",
    "#         real = real.cuda()\n",
    "#         batch_size = real.size(0)\n",
    "\n",
    "#         # Train Discriminator\n",
    "#         noise = torch.randn(batch_size, z_dim, 1, 1).cuda()\n",
    "#         fake = generator(noise)\n",
    "\n",
    "#         disc_real = discriminator(real).reshape(-1)\n",
    "#         disc_fake = discriminator(fake.detach()).reshape(-1)\n",
    "#         loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "#         loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "#         loss_disc = loss_disc_real + loss_disc_fake\n",
    "\n",
    "#         optim_disc.zero_grad()\n",
    "#         loss_disc.backward()\n",
    "#         optim_disc.step()\n",
    "\n",
    "#         # Train Generator\n",
    "#         output = discriminator(fake).reshape(-1)\n",
    "#         loss_gen = criterion(output, torch.ones_like(output))\n",
    "\n",
    "#         optim_gen.zero_grad()\n",
    "#         loss_gen.backward()\n",
    "#         optim_gen.step()\n",
    "\n",
    "#         # Save losses for plotting later\n",
    "#         gen_losses.append(loss_gen.item())\n",
    "#         disc_losses.append(loss_disc.item())\n",
    "\n",
    "#         if idx % 100 == 0:\n",
    "#             print(f\"Epoch [{epoch}/{num_epochs}] Batch {idx}/{len(dataloader)} Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "\n",
    "#     # Save images at the end of each epoch\n",
    "#     with torch.no_grad():\n",
    "#         fake_images = generator(noise).detach().cpu()\n",
    "#         img_grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "#         plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "#         plt.show()\n",
    "# Plotting the Losses\n",
    "# After training is complete, we can plot the generator and discriminator losses to observe the training process and convergence.\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot the losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "# plt.plot(gen_losses, label=\"Generator\")\n",
    "# plt.plot(disc_losses, label=\"Discriminator\")\n",
    "# plt.xlabel(\"Iterations\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# Understanding GAN Convergence\n",
    "# To ascertain the convergence of the GAN training process, observe the following in the plotted losses:\n",
    "\n",
    "# Stable Losses: Both generator and discriminator losses should stabilize over time. Initially, the discriminator loss might be high and the generator loss low, but as training progresses, they should become more stable.\n",
    "# Alternating Improvements: GAN training often involves alternating improvements between the generator and discriminator. This can result in oscillations in the loss curves. Small, steady oscillations can indicate healthy training.\n",
    "# No Mode Collapse: If the generator learns to produce diverse outputs and the discriminator can correctly classify them, the training is likely going well. Mode collapse (when the generator produces limited varieties of outputs) might indicate issues.\n",
    "# Visual Inspection: In addition to loss curves, periodically inspect the generated images. They should improve in quality and realism as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f269039",
   "metadata": {},
   "source": [
    "# Question 2: Fine-tuning Take a ResNet50 model and the database to be used for this question is CIFAR-10.Remove its classification layer and place a 2-layer neural network followed by a Softmax layer. Calculateclassification accuracy on a train set, test set, and plot accuracies over epochs when:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b258769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning a pre-trained ResNet50 model on the CIFAR-10 dataset involves modifying the classification layer to suit the new dataset and training the modified model. Here's how to do it step-by-step:\n",
    "\n",
    "# Step-by-Step Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 dataset and preprocess it.\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Just normalization for testing\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64177ce",
   "metadata": {},
   "source": [
    "# A. The complete network is trained from scratch (i.e, random weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1de822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To train the complete network from scratch with random weights, we'll initialize a ResNet50 model without pre-trained weights and train it on the CIFAR-10 dataset. The overall approach remains similar to what we previously discussed, with the main difference being that we won't load pre-trained weights.\n",
    "\n",
    "# Step-by-Step Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 dataset and preprocess it.\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Just normalization for testing\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# 3. Model Architecture Modification\n",
    "# Initialize a ResNet50 model with random weights and modify its classification layer.\n",
    "# from torchvision import models\n",
    "\n",
    "# # Load ResNet50 with random weights\n",
    "# resnet50 = models.resnet50(pretrained=False)\n",
    "\n",
    "# # Modify the fully connected layer\n",
    "# num_ftrs = resnet50.fc.in_features\n",
    "# resnet50.fc = nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(512, 10),\n",
    "#     nn.Softmax(dim=1)\n",
    "# )\n",
    "\n",
    "# resnet50 = resnet50.cuda()\n",
    "# 4. Training the Model\n",
    "# Set up the loss function, optimizer, and training loop.\n",
    "# # Loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
    "\n",
    "# # Function to train the model\n",
    "# def train_model(model, criterion, optimizer, trainloader, testloader, num_epochs=10):\n",
    "#     train_acc = []\n",
    "#     test_acc = []\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         for inputs, labels in trainloader:\n",
    "#             inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         train_acc.append(100 * correct / total)\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Train Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#         # Evaluate on the test set\n",
    "#         model.eval()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in testloader:\n",
    "#                 inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         test_acc.append(100 * correct / total)\n",
    "#         print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#     return train_acc, test_acc\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# train_acc, test_acc = train_model(resnet50, criterion, optimizer, trainloader, testloader, num_epochs=num_epochs)\n",
    "# 5. Plotting the Accuracies\n",
    "# After training, plot the training and testing accuracies over epochs.\n",
    "# # Plot accuracies\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1, num_epochs + 1)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
    "# plt.plot(epochs, test_acc, 'r', label='Testing accuracy')\n",
    "# plt.title('Training and Testing Accuracy Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785ec96",
   "metadata": {},
   "source": [
    "# B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained (i.e, weights of layers of ResNet50 are kept frozen and unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d06eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fine-tune a pre-trained ResNet50 model with weights from ImageNet on the CIFAR-10 dataset while keeping the ResNet50 layers frozen, you can follow these steps:\n",
    "\n",
    "# Step-by-Step Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 dataset and preprocess it.\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Just normalization for testing\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# 3. Model Architecture Modification\n",
    "# Load a pre-trained ResNet50 model with ImageNet weights, freeze its layers, and add a new 2-layer neural network followed by a Softmax layer.\n",
    "# from torchvision import models\n",
    "\n",
    "# # Load pre-trained ResNet50\n",
    "# resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# # Freeze all layers\n",
    "# for param in resnet50.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Modify the fully connected layer\n",
    "# num_ftrs = resnet50.fc.in_features\n",
    "# resnet50.fc = nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(512, 10),\n",
    "#     nn.Softmax(dim=1)\n",
    "# )\n",
    "\n",
    "# resnet50 = resnet50.cuda()\n",
    "# 4. Training the Model\n",
    "# Set up the loss function, optimizer, and training loop.\n",
    "# # Loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# # Function to train the model\n",
    "# def train_model(model, criterion, optimizer, trainloader, testloader, num_epochs=10):\n",
    "#     train_acc = []\n",
    "#     test_acc = []\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         for inputs, labels in trainloader:\n",
    "#             inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         train_acc.append(100 * correct / total)\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Train Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#         # Evaluate on the test set\n",
    "#         model.eval()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#          with torch.no_grad():\n",
    "#             for inputs, labels in testloader:\n",
    "#                 inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         test_acc.append(100 * correct / total)\n",
    "#         print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#     return train_acc, test_acc\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# train_acc, test_acc = train_model(resnet50, criterion, optimizer, trainloader, testloader, num_epochs=num_epochs)\n",
    "\n",
    "# 5. Plotting the Accuracies\n",
    "# After training, plot the training and testing accuracies over epochs.\n",
    "# # Plot accuracies\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1, num_epochs + 1)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
    "# plt.plot(epochs, test_acc, 'r', label='Testing accuracy')\n",
    "# plt.title('Training and Testing Accuracy Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506b4b6",
   "metadata": {},
   "source": [
    "# C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of layers of ResNet50 are also updated now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc0562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To fine-tune a pre-trained ResNet50 model on the CIFAR-10 dataset with all layers being updated, follow these steps. This process will involve loading the pre-trained ResNet50 model, modifying its classification layer, and training the entire model, including the ResNet50 layers.\n",
    "\n",
    "# Step-by-Step Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 dataset and preprocess it.\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Just normalization for testing\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# 3. Model Architecture Modification\n",
    "# Load a pre-trained ResNet50 model with ImageNet weights, and modify its classification layer.\n",
    "# from torchvision import models\n",
    "\n",
    "# # Load pre-trained ResNet50\n",
    "# resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# # Modify the fully connected layer\n",
    "# num_ftrs = resnet50.fc.in_features\n",
    "# resnet50.fc = nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(512, 10),\n",
    "#     nn.Softmax(dim=1)\n",
    "# )\n",
    "\n",
    "# resnet50 = resnet50.cuda()\n",
    "# 5. Plotting the Accuracies\n",
    "# After training, plot the training and testing accuracies over epochs.\n",
    "# # Plot accuracies\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1, num_epochs + 1)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
    "# plt.plot(epochs, test_acc, 'r', label='Testing accuracy')\n",
    "# plt.title('Training and Testing Accuracy Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecbf21",
   "metadata": {},
   "source": [
    "# D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full credit for this part, the accuracy on the test set should be more than what was reported in part 3. You may build upon part(3) to propose your own algorithm. Explain why your proposed algorithm is working better. You may use any training data as long as it involves using other datasets (on which youâ€™ll adapt CIFAR-10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f21386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To propose a domain adaptation algorithm that improves the accuracy of a ResNet50 model on the CIFAR-10 dataset, we can use a technique called Unsupervised Domain Adaptation (UDA). UDA involves training a model on a labeled source dataset and adapting it to perform well on a different, unlabeled target dataset. For our case, we'll use a combination of CIFAR-10 and another similar dataset such as CIFAR-100. The key idea is to leverage domain-invariant features that generalize well across both datasets.\n",
    "\n",
    "# Proposed Domain Adaptation Algorithm\n",
    "# Algorithm: Adversarial Domain Adaptation with a Domain Classifier\n",
    "\n",
    "# Pre-training on Source Data (CIFAR-10)\n",
    "\n",
    "# Start with a pre-trained ResNet50 model on ImageNet.\n",
    "# Fine-tune it on CIFAR-10 to obtain a baseline model.\n",
    "# Domain Adaptation using CIFAR-100\n",
    "\n",
    "# Introduce a domain classifier to distinguish between the source (CIFAR-10) and target (CIFAR-100) domains.\n",
    "# Train the feature extractor (ResNet50) to confuse the domain classifier while the domain classifier is trained to distinguish between the two domains. This encourages the feature extractor to learn domain-invariant features.\n",
    "# Use adversarial training to minimize the domain classification loss and the CIFAR-10 classification loss simultaneously.\n",
    "# Combining the Losses\n",
    "\n",
    "# Use a weighted sum of the classification loss on CIFAR-10 and the domain classification loss.\n",
    "# Implementation\n",
    "# 1. Setup the Environment\n",
    "# Ensure you have the necessary libraries installed.\n",
    "# pip install torch torchvision matplotlib\n",
    "# 2. Data Preparation\n",
    "# Load the CIFAR-10 and CIFAR-100 datasets and preprocess them.\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Just normalization for testing\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# cifar100_trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "# cifar100_trainloader = DataLoader(cifar100_trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "# 3. Model Architecture Modification\n",
    "# Load a pre-trained ResNet50 model with ImageNet weights, modify its classification layer, and add a domain classifier.\n",
    "# from torchvision import models\n",
    "\n",
    "# class ResNet50WithDomainClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ResNet50WithDomainClassifier, self).__init__()\n",
    "#         self.feature_extractor = models.resnet50(pretrained=True)\n",
    "#         num_ftrs = self.feature_extractor.fc.in_features\n",
    "#         self.feature_extractor.fc = nn.Identity()\n",
    "\n",
    "#         self.class_classifier = nn.Sequential(\n",
    "#             nn.Linear(num_ftrs, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(512, 10),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.domain_classifier = nn.Sequential(\n",
    "#             nn.Linear(num_ftrs, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(512, 2),  # 2 domains: CIFAR-10 and CIFAR-100\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.feature_extractor(x)\n",
    "#         class_output = self.class_classifier(features)\n",
    "#         domain_output = self.domain_classifier(features)\n",
    "#         return class_output, domain_output\n",
    "\n",
    "# model = ResNet50WithDomainClassifier().cuda()\n",
    "# . Training the Model\n",
    "# Set up the loss functions, optimizers, and training loop.\n",
    "# # Loss functions and optimizers\n",
    "# criterion_class = nn.CrossEntropyLoss()\n",
    "# criterion_domain = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Training loop with domain adaptation\n",
    "# def train_domain_adaptation(model, criterion_class, criterion_domain, optimizer, trainloader, cifar100_trainloader, testloader, num_epochs=10):\n",
    "#     train_acc = []\n",
    "#     test_acc = []\n",
    "#     domain_labels = torch.cat((torch.zeros(len(trainloader.dataset)), torch.ones(len(cifar100_trainloader.dataset)))).long().cuda()\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         cifar100_iter = iter(cifar100_trainloader)\n",
    "        \n",
    "#         for i, (inputs, labels) in enumerate(trainloader):\n",
    "#             try:\n",
    "#                 inputs_cifar100, _ = next(cifar100_iter)\n",
    "#             except StopIteration:\n",
    "#                 cifar100_iter = iter(cifar100_trainloader)\n",
    "#                 inputs_cifar100, _ = next(cifar100_iter)\n",
    "\n",
    "#             inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#             inputs_cifar100 = inputs_cifar100.cuda()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass through model\n",
    "#             class_output, domain_output_cifar10 = model(inputs)\n",
    "#             _, domain_output_cifar100 = model(inputs_cifar100)\n",
    "\n",
    "#             # Calculate losses\n",
    "#             loss_class = criterion_class(class_output, labels)\n",
    "#             domain_labels_cifar10 = torch.zeros(inputs.size(0)).long().cuda()\n",
    "#             domain_labels_cifar100 = torch.ones(inputs_cifar100.size(0)).long().cuda()\n",
    "#             loss_domain = criterion_domain(domain_output_cifar10, domain_labels_cifar10) + criterion_domain(domain_output_cifar100, domain_labels_cifar100)\n",
    "\n",
    "#             # Combine losses and backpropagate\n",
    "#             loss = loss_class + loss_domain\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = class_output.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         train_acc.append(100 * correct / total)\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Train Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#         # Evaluate on the test set\n",
    "#         model.eval()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in testloader:\n",
    "#                 inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#                 class_output, _ = model(inputs)\n",
    "#                 _, predicted = class_output.max(1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         test_acc.append(100 * correct / total)\n",
    "#         print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "#     return train_acc, test_acc\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# train_acc, test_acc = train_domain_adaptation(model, criterion_class, criterion_domain, optimizer, trainloader, cifar100_trainloader, testloader, num_epochs=num_epochs)\n",
    "# 5. Plotting the Accuracies\n",
    "# After training, plot the training and testing accuracies over epochs.\n",
    "# # Plot accuracies\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1, num_epochs + 1)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, train_acc, 'b', label='Training accuracy')\n",
    "# plt.plot(epochs, test_acc, 'r', label='Testing accuracy')\n",
    "# plt.title('Training and Testing Accuracy Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880df3f4",
   "metadata": {},
   "source": [
    "# Use cases found for GAN\n",
    "# ! Super-resolution: increasing the resolution of input image%\n",
    "# ! Colorise blank and white image%\n",
    "# ! image inpainting - fill missing blocks in image%\n",
    "# ! Anime face generatio\n",
    "# ! font generatio\n",
    "# ! style transfe\n",
    "# ! human face generatio\n",
    "# ! image to emoj'\n",
    "# ! GAN for data augmentatio\n",
    "# ! Face ageing GA\n",
    "# ! front facial view generation from images provided of different side%\n",
    "# ! Photo blending- blending 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b6fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GANs have a wide range of applications across various domains due to their ability to generate high-quality images. Here are some key use cases:\n",
    "\n",
    "# Super-Resolution: GANs can increase the resolution of low-resolution images, making them clearer and more detailed. This is particularly useful in medical imaging, satellite imaging, and enhancing old photographs.\n",
    "\n",
    "# Colorizing Black and White Images: GANs can add color to black and white images, bringing old photographs or movies to life with realistic colors.\n",
    "\n",
    "# Image Inpainting: GANs can fill in missing parts of an image. This is useful for restoring damaged photographs, removing objects, or filling in gaps in images.\n",
    "\n",
    "# Anime Face Generation: GANs can generate anime-style faces, which can be used in the creation of new characters for comics, games, and animations.\n",
    "\n",
    "# Font Generation: GANs can create new fonts based on a few examples, which is helpful for designers looking to create unique typography styles.\n",
    "\n",
    "# Style Transfer: GANs can apply the style of one image (e.g., a painting) to another image (e.g., a photograph), blending artistic styles with real-world images.\n",
    "\n",
    "# Human Face Generation: GANs can generate realistic human faces, which can be used in virtual reality, video games, and even creating synthetic data for training AI models.\n",
    "\n",
    "# Image to Emoji: GANs can convert images of human faces into corresponding emojis, creating personalized emojis for users.\n",
    "\n",
    "# GAN for Data Augmentation: GANs can generate synthetic data to augment datasets, improving the performance of machine learning models by providing more diverse training examples.\n",
    "\n",
    "# Face Aging GAN: GANs can simulate the aging process on human faces, which can be used in forensics, entertainment, and understanding aging patterns.\n",
    "\n",
    "# Front Facial View Generation: GANs can generate frontal views of faces from images taken from different angles, useful in facial recognition systems and 3D face reconstruction.\n",
    "\n",
    "# Photo Blending: GANs can blend two images together, creating composite images that combine elements from both, useful in creative arts and advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe2232c",
   "metadata": {},
   "source": [
    "# Coding Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58c01f",
   "metadata": {},
   "source": [
    "# 1. Data Augmentation Function for GAN Training Write a Python function that generates augmented data for training a GAN. The function should take an image dataset as input and apply data augmentation techniques commonly used in GAN training, such as random rotation, flipping, and cropping. The function should return the augmented dataset. You can use popular image-processing libraries like OpenCV or PIL to perform these augmentations.Ensure that the function allows customization of augmentation parameters, such as rotation angles,flip probability, and crop size1. Data Augmentation Function for GAN Training .Write a Python function that generates augmented data for training a GAN. The function should take an image dataset as input and apply data augmentation techniques commonly used in GAN training,such as random rotation, flipping, and cropping. The function should return the augmented dataset.You can use popular image-processing libraries like OpenCV or PIL to perform these augmentations.Ensure that the function allows customization of augmentation parameters, such as rotation angles,flip probability, and crop size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5819f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a Python function to perform data augmentation for GAN training using the popular image-processing library PIL. This function will apply random rotation, flipping, and cropping to an image dataset. The function also allows customization of augmentation parameters such as rotation angles, flip probability, and crop size.\n",
    "# from PIL import Image, ImageOps\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from torchvision import transforms\n",
    "\n",
    "# def augment_image(image, rotation_range=30, flip_prob=0.5, crop_size=(28, 28)):\n",
    "#     \"\"\"\n",
    "#     Apply data augmentation techniques to a single image.\n",
    "    \n",
    "#     Args:\n",
    "#     - image (PIL.Image): Input image to be augmented.\n",
    "#     - rotation_range (int): Degree range for random rotations.\n",
    "#     - flip_prob (float): Probability of flipping the image.\n",
    "#     - crop_size (tuple): Desired crop size (width, height).\n",
    "    \n",
    "#     Returns:\n",
    "#     - PIL.Image: Augmented image.\n",
    "#     \"\"\"\n",
    "#     # Random rotation\n",
    "#     if rotation_range > 0:\n",
    "#         angle = random.uniform(-rotation_range, rotation_range)\n",
    "#         image = image.rotate(angle)\n",
    "    \n",
    "#     # Random horizontal flip\n",
    "#     if random.random() < flip_prob:\n",
    "#         image = ImageOps.mirror(image)\n",
    "    \n",
    "#     # Random crop\n",
    "#     width, height = image.size\n",
    "#     crop_width, crop_height = crop_size\n",
    "#     left = random.randint(0, width - crop_width)\n",
    "#     top = random.randint(0, height - crop_height)\n",
    "#     right = left + crop_width\n",
    "#     bottom = top + crop_height\n",
    "#     image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "#     return image\n",
    "\n",
    "# def augment_dataset(dataset, rotation_range=30, flip_prob=0.5, crop_size=(28, 28)):\n",
    "#     \"\"\"\n",
    "#     Apply data augmentation techniques to a dataset of images.\n",
    "    \n",
    "#     Args:\n",
    "#     - dataset (list of PIL.Image): List of images to be augmented.\n",
    "#     - rotation_range (int): Degree range for random rotations.\n",
    "#     - flip_prob (float): Probability of flipping the image.\n",
    "#     - crop_size (tuple): Desired crop size (width, height).\n",
    "    \n",
    "#     Returns:\n",
    "#     - list of PIL.Image: Augmented dataset.\n",
    "#     \"\"\"\n",
    "#     augmented_dataset = []\n",
    "#     for image in dataset:\n",
    "#         augmented_image = augment_image(image, rotation_range, flip_prob, crop_size)\n",
    "#         augmented_dataset.append(augmented_image)\n",
    "#     return augmented_dataset\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load dataset (example with CIFAR-10)\n",
    "#     from torchvision.datasets import CIFAR10\n",
    "#     dataset = CIFAR10(root='./data', train=True, download=True)\n",
    "#     images = [Image.fromarray(img) for img, _ in dataset]\n",
    "    \n",
    "#     # Augment dataset\n",
    "#     rotation_range = 30\n",
    "#     flip_prob = 0.5\n",
    "#     crop_size = (28, 28)\n",
    "#     augmented_images = augment_dataset(images, rotation_range, flip_prob, crop_size)\n",
    "    \n",
    "#     # Display some augmented images\n",
    "#     for i in range(5):\n",
    "#         augmented_images[i].show()\n",
    "# Explanation:\n",
    "# augment_image Function:\n",
    "\n",
    "# Takes an input image and applies random rotation, flipping, and cropping.\n",
    "# Allows customization of augmentation parameters such as rotation_range, flip_prob, and crop_size.\n",
    "# augment_dataset Function:\n",
    "\n",
    "# Takes a list of images (dataset) and applies the augment_image function to each image in the dataset.\n",
    "# Returns the augmented dataset.\n",
    "# Example Usage:\n",
    "\n",
    "# Loads the CIFAR-10 dataset using torchvision.datasets.\n",
    "# Converts the dataset images from NumPy arrays to PIL Images.\n",
    "# Applies data augmentation with specified parameters.\n",
    "# Displays some augmented images to verify the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f72517",
   "metadata": {},
   "source": [
    "# 2.Create a simple discriminator model using tensorflow keras which can classify a image as real or fake. You can use random noise same size as the image to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169309ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple discriminator model using TensorFlow Keras involves building a neural network that can classify images as real or fake. The discriminator model typically uses a convolutional neural network (CNN) to process the images. Below is an example of how you can create such a model and train it using random noise images as fake samples and actual dataset images as real samples.\n",
    "\n",
    "# Implementation\n",
    "# First, ensure you have TensorFlow installed:\n",
    "#     pip install tensorflow\n",
    "# Here is the code to create and train the discriminator model:\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# import numpy as np\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# def build_discriminator(input_shape):\n",
    "#     \"\"\"\n",
    "#     Builds a simple discriminator model.\n",
    "    \n",
    "#     Args:\n",
    "#     - input_shape (tuple): Shape of the input image.\n",
    "    \n",
    "#     Returns:\n",
    "#     - tf.keras.Model: Discriminator model.\n",
    "#     \"\"\"\n",
    "#     model = models.Sequential()\n",
    "    \n",
    "#     model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "    \n",
    "#     model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "    \n",
    "#     model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Dropout(0.3))\n",
    "    \n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Define input shape (e.g., for CIFAR-10: 32x32x3)\n",
    "# input_shape = (32, 32, 3)\n",
    "# discriminator = build_discriminator(input_shape)\n",
    "\n",
    "# # Compile the discriminator\n",
    "# discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Print the model summary\n",
    "# discriminator.summary()\n",
    "\n",
    "# # Example: Generate random noise and real images for training\n",
    "# import numpy as np\n",
    "\n",
    "# def generate_real_samples(dataset, n_samples):\n",
    "#     \"\"\"\n",
    "#     Select a batch of random real images from the dataset.\n",
    "    \n",
    "#     Args:\n",
    "#     - dataset (numpy array): Dataset of real images.\n",
    "#     - n_samples (int): Number of samples to generate.\n",
    "    \n",
    "#     Returns:\n",
    "#     - numpy array: Real images.\n",
    "#     - numpy array: Labels (1s).\n",
    "#     \"\"\"\n",
    "#     idx = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "#     X = dataset[idx]\n",
    "#     y = np.ones((n_samples, 1))\n",
    "#     return X, y\n",
    "\n",
    "# def generate_fake_samples(n_samples, input_shape):\n",
    "#     \"\"\"\n",
    "#     Generate a batch of random fake images (noise).\n",
    "    \n",
    "#     Args:\n",
    "#     - n_samples (int): Number of samples to generate.\n",
    "#     - input_shape (tuple): Shape of the input image.\n",
    "    \n",
    "#     Returns:\n",
    "#     - numpy array: Fake images (random noise).\n",
    "#     - numpy array: Labels (0s).\n",
    "#     \"\"\"\n",
    "#     X = np.random.rand(n_samples, *input_shape)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "#     return X, y\n",
    "\n",
    "# # Load CIFAR-10 dataset for example\n",
    "# (X_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# # Normalize images\n",
    "# X_train = X_train.astype('float32') / 255.0\n",
    "\n",
    "# # Generate real and fake samples\n",
    "# n_samples = 128\n",
    "# real_images, real_labels = generate_real_samples(X_train, n_samples)\n",
    "# fake_images, fake_labels = generate_fake_samples(n_samples, input_shape)\n",
    "\n",
    "# # Train the discriminator on real and fake samples\n",
    "# X, y = np.vstack((real_images, fake_images)), np.vstack((real_labels, fake_labels))\n",
    "# discriminator.fit(X, y, epochs=10, batch_size=64)\n",
    "# Explanation:\n",
    "# Discriminator Model (build_discriminator function):\n",
    "\n",
    "# The discriminator model is built using a series of convolutional layers, followed by LeakyReLU activation and dropout for regularization.\n",
    "# The final dense layer outputs a single value with a sigmoid activation function, indicating whether the input image is real or fake.\n",
    "# Compilation:\n",
    "\n",
    "# The discriminator model is compiled using the Adam optimizer and binary cross-entropy loss, which is suitable for binary classification tasks.\n",
    "# Sample Generation Functions:\n",
    "\n",
    "# generate_real_samples selects a batch of random real images from the dataset.\n",
    "# generate_fake_samples generates a batch of random noise images of the same shape as the real images.\n",
    "# Training the Discriminator:\n",
    "\n",
    "# Real and fake samples are generated and combined into a single training set.\n",
    "# The discriminator is trained on this combined set to distinguish between real and fake images.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c65c9e",
   "metadata": {},
   "source": [
    "# 3.Create a generator model with uses transpose convolution to generate 32 x 32 x 3 images from random noise. In this question you can just define the model architecture for the generator and maken sure that the model is generating the desired image size , you can take a latent space dimension as a array of 100 float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4206170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# def build_generator(latent_dim):\n",
    "#     \"\"\"\n",
    "#     Builds a generator model to generate 32x32x3 images from random noise.\n",
    "    \n",
    "#     Args:\n",
    "#     - latent_dim (int): Dimension of the latent space.\n",
    "    \n",
    "#     Returns:\n",
    "#     - tf.keras.Model: Generator model.\n",
    "#     \"\"\"\n",
    "#     model = models.Sequential()\n",
    "    \n",
    "#     # Dense layer to project and reshape into a large enough feature map\n",
    "#     model.add(layers.Dense(4 * 4 * 256, use_bias=False, input_shape=(latent_dim,)))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     model.add(layers.LeakyReLU())\n",
    "#     model.add(layers.Reshape((4, 4, 256)))\n",
    "    \n",
    "#     # Transpose convolution layers\n",
    "#     model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     model.add(layers.LeakyReLU())\n",
    "    \n",
    "#     model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     model.add(layers.LeakyReLU())\n",
    "    \n",
    "#     model.add(layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     model.add(layers.LeakyReLU())\n",
    "    \n",
    "#     model.add(layers.Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Define latent space dimension\n",
    "# latent_dim = 100\n",
    "# generator = build_generator(latent_dim)\n",
    "\n",
    "# # Print the model summary\n",
    "# generator.summary()\n",
    "\n",
    "# # Example: Generate an image from random noise\n",
    "# import numpy as np\n",
    "\n",
    "# random_noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "# generated_image = generator(random_noise)\n",
    "\n",
    "# print(f\"Generated image shape: {generated_image.shape}\")\n",
    "# exxplanation:\n",
    "# Generator Model (build_generator function):\n",
    "\n",
    "# The model starts with a dense layer that projects the latent space into a feature map of shape \n",
    "\n",
    "\n",
    "# 4Ã—4Ã—256.\n",
    "# This is followed by a series of transpose convolutional layers (Conv2DTranspose), each upsampling the feature maps by a factor of 2.\n",
    "# Batch normalization and LeakyReLU activation are applied after each transpose convolution layer to help stabilize training and add non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515a9ed",
   "metadata": {},
   "source": [
    "# Implementing a Minimax Loss Function for GANs Write a Python function that calculates the Minimax loss for a GAN. The function should take as input the predictions (scores) from a discriminator and return the Minimax loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement a Minimax loss function for GANs, we need to calculate the loss for both the discriminator and the generator. The Minimax loss for the discriminator is calculated using the binary cross-entropy loss, where the discriminator aims to maximize the log probability of correctly identifying real images and minimize the log probability of incorrectly identifying fake images. For the generator, the Minimax loss is also a binary cross-entropy loss, but with the objective to maximize the log probability of the discriminator classifying the fake images as real.\n",
    "\n",
    "# Here is the Python function to calculate the Minimax loss for both the discriminator and the generator:\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def minimax_loss(discriminator_real_outputs, discriminator_fake_outputs):\n",
    "#     \"\"\"\n",
    "#     Calculates the Minimax loss for GANs.\n",
    "    \n",
    "#     Args:\n",
    "#     - discriminator_real_outputs (tf.Tensor): Discriminator predictions for real images.\n",
    "#     - discriminator_fake_outputs (tf.Tensor): Discriminator predictions for fake images.\n",
    "    \n",
    "#     Returns:\n",
    "#     - discriminator_loss (tf.Tensor): Minimax loss for the discriminator.\n",
    "#     - generator_loss (tf.Tensor): Minimax loss for the generator.\n",
    "#     \"\"\"\n",
    "#     # Binary cross-entropy loss for real and fake images\n",
    "#     bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "#     # Discriminator loss: Maximize log(D(x)) + log(1 - D(G(z)))\n",
    "#     real_labels = tf.ones_like(discriminator_real_outputs)\n",
    "#     fake_labels = tf.zeros_like(discriminator_fake_outputs)\n",
    "    \n",
    "#     d_loss_real = bce(real_labels, discriminator_real_outputs)\n",
    "#     d_loss_fake = bce(fake_labels, discriminator_fake_outputs)\n",
    "    \n",
    "#     discriminator_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "#     # Generator loss: Minimize log(1 - D(G(z))) which is equivalent to maximize log(D(G(z)))\n",
    "#     g_loss = bce(real_labels, discriminator_fake_outputs)\n",
    "    \n",
    "#     return discriminator_loss, g_loss\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Simulate some predictions from the discriminator for real and fake images\n",
    "#     discriminator_real_outputs = tf.constant([[0.9], [0.8], [0.7]], dtype=tf.float32)\n",
    "#     discriminator_fake_outputs = tf.constant([[0.1], [0.2], [0.3]], dtype=tf.float32)\n",
    "    \n",
    "#     d_loss, g_loss = minimax_loss(discriminator_real_outputs, discriminator_fake_outputs)\n",
    "    \n",
    "#     print(f\"Discriminator Loss: {d_loss.numpy()}\")\n",
    "#     print(f\"Generator Loss: {g_loss.numpy()}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
